# __2022 Summer Data Study__
## 2022ë…„ ì—¬ë¦„ë°©í•™ ë°ì´í„° ìŠ¤í„°ë””
>   [2022_07_22](#2022_07_22)
>   [2022_07_23](#2022_07_23)
>   [2022_07_29](#2022_07_29)
>   [2022_07_31](#2022_07_31)
***
- ### ___2022_07_22___
    #### ğŸ“Œ BeautifulSoup ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ 7ì›” 1ì¼ìì˜ ëª¨ë“  ë‰´ìŠ¤ ìˆ˜ì§‘ ğŸ“Œ

    ë„¤ì´ë²„ ë‰´ìŠ¤ ì£¼ì†Œë¥¼ requestë¡œ ìš”ì²­í•˜ì˜€ì„ ë•Œ ì˜¤ë¥˜ê°€ ë°œìƒ
    ì„œë²„ì—ì„œ ì‚¬ìš©ì ì†Œí”„íŠ¸ì›¨ì–´ì˜ ì‹ë³„ ì •ë³´ì¸ User-Agent ì—†ì´ HTTP ìš”ì²­ì„ í•˜ë©´ ì˜¤ë¥˜ê°€ ë°œìƒ
    User-Agent ê°’ì„ í¬í•¨í•˜ëŠ” header ì¶”ê°€í•˜ì—¬ ì˜¤ë¥˜ í•´ê²° (í¬ë¡¬ ì‚¬ìš©)
    ```python
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}
    res = requests.get(URL, headers=headers)
    ```

    í•´ë‹¹ ë‚ ì§œì˜ ì²«ë²ˆì§¸ í˜ì´ì§€ URLê³¼ ê·¸ í˜ì´ì§€ í•˜ë‹¨ì˜ í˜ì´ì§€ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ì˜ urlì„ page ë¦¬ìŠ¤íŠ¸ì— append
    ```python
    page = ['https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid2=229&sid1=105&date=20220701']
    for li in soup.select('#main_content > div.paging > a'):
        page.append('https://news.naver.com/main/list.naver' + li['href'])
    ```
    page ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ í˜ì´ì§€ì— ìˆëŠ” ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ forë¬¸ìœ¼ë¡œ ëŒë¦¬ëŠ” 'í˜ì´ì§€ íƒìƒ‰' forë¬¸ ì‚¬ìš©
    ```python
    for li in soup.select('#main_content > div > ul > li'):
        url = li.a['href']
    ```

    ë¦¬ìŠ¤íŠ¸ lì— 'í˜ì´ì§€ íƒìƒ‰' forë¬¸ìœ¼ë¡œ ì–»ì€ title, date, contents ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ appendí•œ í›„ forë¬¸ ì¢…ë£Œ í›„ pandasë¥¼ ì´ìš©í•˜ì—¬ DataFrameìœ¼ë¡œ ì •ë¦¬í•˜ê³  ì—‘ì…€(naver_news.xlsx)ë¡œ ì €ì¥
    ```python
    l.append([title, date, contents])
    .
    .
    .
    df = pd.DataFrame(l, columns = ['title', 'url', 'contents'])
    df.to_excel('naver_news.xlsx', index = False) 
    ```
***
- ### ___2022_07_23___
    #### ğŸ“Œ 6ì›” í•œ ë‹¬ì¹˜ ë‰´ìŠ¤ ìˆ˜ì§‘ ğŸ“Œ
    
    6ì›” í•œ ë‹¬ì´ 30ì¼ì¸ê±¸ ë°˜ì˜í•˜ì—¬ for, rangeë¬¸ìœ¼ë¡œ 30ì¼ì¹˜ ë‰´ìŠ¤ urlì„ ë§Œë“¤ì–´ day_url ë¦¬ìŠ¤íŠ¸ì— append
    ```python
    for day in range(30):
    day_url.append('https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid2=229&sid1=105&date='+ str(20220601 + day))
    ```
***
- ### ___2022_07_29___
    #### ğŸ“Œ titleê³¼ date ìˆ˜ì§‘ ë°©ì‹ ë³€ê²½ ğŸ“Œ
    
    ê¸°ì¡´ì—ëŠ” ë‰´ìŠ¤ ê°œë³„ í˜ì´ì§€ ì•ˆì—ì„œ titleê³¼ dateë¥¼ ìˆ˜ì§‘
    ì´ ê³¼ì •ì—ì„œ ì–¸ë¡ ì‚¬ë§ˆë‹¤ selectorê°€ ë‹¬ë¼ì„œ ê·¸ ì¢…ë¥˜ë¥¼ ëª¨ë‘ ì°¾ì€ í›„ try, exceptë¬¸ìœ¼ë¡œ ì²˜ë¦¬
    ```python
    #title
    try :
        title = soup.select_one('#ct > div > div > h2').text.strip()
    except:
        title = soup.select_one('#content > div > div > div > div > h4').text.strip()
    #date
    try:
        date = soup.select_one('#ct > div > div > div > div > span').text.strip()
    except:
        date = soup.select_one('#content > div > div> div > div> div > span').text.strip()
        if date == 'ìƒˆë¡œìš´ ë‰´ìŠ¤':
            date = soup.select_one('#content > div.end_ct > div > div.article_info > span > em').text.strip()
        else:
            list(date)
            date = date[5:]
            str(date)
    ```

    ìœ„ì˜ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ë” ë§ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•  ë•Œ ë¬¸ì œê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ìˆê³  íš¨ìœ¨ì ì´ì§€ ëª»í•˜ê¸°ì— ë‰´ìŠ¤ ê°œë³„ í˜ì´ì§€ê°€ ì•„ë‹Œ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ê°€ ë³´ì´ëŠ” í˜ì´ì§€ì—ì„œ ê¸°ë³¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ë„ë¡ ìˆ˜ì • (ê·¸ëŸ¬ë‚˜ í˜ì´ì§€ ë‚´ë¶€ì—ì„œ ìˆ˜ì§‘í•˜ëŠ” content í•­ëª©ì€ ì•„ì§ ìˆ˜ì •í•˜ì§€ ëª»í•¨)
    ```python
    def basic_info(li):
        url = li.a['href']
        for t in li.select('#main_content > div > ul > li > dl > dt > a'):
            title = t.text.strip()
        date = li.select_one('#main_content > div > ul > li > dl > dd > span.date').text.strip()

        return title, date, url
    ```
***
- ### ___2022_07_31___
    #### ğŸ“Œ MySQLì— ë°ì´í„° ì •ë¦¬ ğŸ“Œ
    
    ì—‘ì…€ì˜ í–‰ì˜ í•œê³„ëŠ” 1048576ê°œì´ê¸° ë•Œë¬¸ì— ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸°ì— ë¬´ë¦¬ê°€ ìˆê¸°ì— ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
    MySQLì— web ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±, news í…Œì´ë¸” ìƒì„±, publisher, title, date í•„ë“œ ìƒì„±
    ```sql
    CREATE DATABASE web

    USE web

    CREATE TABLE `test`.`news` (
        `publisher` VARCHAR(20) NOT NULL,
        `title` VARCHAR(100) NOT NULL,
        `date` VARCHAR(30) NOT NULL);
    ```

    pythonìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•˜ì—¬ pymysql ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©
    ```
    pip install PyMySQL
    ```

    MySQLì— ì—°ê²°í•  ë•Œ í•„ìš”í•œ db, host, user, password, port, charset ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬í˜•ìœ¼ë¡œ mysql_user_info.pyë¡œ ë¯¸ë¦¬ ì €ì¥í•˜ì˜€ë‹¤ê°€ naver_news_detail.pyì—ì„œ import í•˜ì—¬ ì‚¬ìš©
    ```python
    user_info = {'db' : 'web', 'host' : '127.0.0.1', 'user' : 'root', 'passwd' : 'DB_PASSWORD', 'port' : 3306, 'charset' : 'utf8'}
    ```

    ```python
    import mysql_user_info
    ```

    with asë¬¸ì„ ì´ìš©í•˜ì—¬ clos()ë¬¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ë¨
    ```python
    def insert_data(publisher, title, date):
    user = mysql_user_info.user_info
    db = pymysql.connect(db=user['db'], host=user['host'], user=user['user'], passwd=user['passwd'], port=user['port'], charset=user['charset'])

    sql = 'INSERT INTO news (publisher, title, date) VALUES (%s, %s, %s)'

    with db:
        with db.cursor() as cursor:
            cursor.execute(sql, (publisher, title, date))
            db.commit()
    ```

    time ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì½”ë“œ ì‹¤í–‰ì‹œê°„ ì¸¡ì •
    (6ì›” í•œ ë‹¬ì¹˜ë¥¼ contentsë¥¼ í•¨ê»˜ ìˆ˜ì§‘í•˜ë©´ ì•½ 10ë¶„ ì •ë„ ì†Œìš”, contentsë¥¼ ìˆ˜ì§‘ ì•ˆí•˜ì˜€ì„ ë•Œ 68.97558355331421ì´ˆ ì†Œìš”)
    ```python
    import time

    start_time = time.time()
    .
    .
    .
    print(f'Time : {time.time() - start_time}')
    ```
